{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f839438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2047d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xlrd in c:\\programdata\\anaconda3\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d83db1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Times_job_data():\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    def extracig_data():\n",
    "        start_url=\"https://www.timesjobs.com/candidate/job-search.html?from=submit&searchType=Home_Search&luceneResultSize=25&postWeek=60&cboPresFuncArea=35&pDate=Y&sequence=\"\n",
    "        end_url=\"&startPage=\"\n",
    "        mylst=[]\n",
    "        seq=1\n",
    "        for items in range(1,41): ## Using for loop and setting its range till where you want to generate link.\n",
    "            url=start_url+str(items)+end_url+str(seq)\n",
    "            if items%10==0:\n",
    "                seq=seq+10\n",
    "            final_url=url\n",
    "            page=requests.get(final_url).text  ### extracting the html code of entire page.The output will be in str type.\n",
    "            page_code=BeautifulSoup(page,'lxml') ##Using BeautifulSoup to convert html code present in str type to beautifulSoup to perform operations on it.\n",
    "            divs=page_code.find_all('li',class_='clearfix job-bx wht-shd-bx') ##extracting html codes of all divisions prsent on the page.The output will be in list format.  \n",
    "            for items in divs: ##using loop for performing operations on one by one division code present in the above list \n",
    "                jobtitle=items.find('a').text ## extracting job  title\n",
    "                job_title=jobtitle.strip()                                                                ### JOB TITLE\n",
    "                com_name=items.find('h3',class_='joblist-comp-name').text\n",
    "                company_name=com_name.strip() ## extracting company name                                  ### COMPANY NAME\n",
    "                exp=items.find('li').text ## extracting job experince\n",
    "                pattern='\\d+\\s+[-]+\\s+\\d+\\s+\\w+'\n",
    "                m=re.findall(pattern,exp)\n",
    "                experince=''\n",
    "                for n in m:\n",
    "                    experince=n                                                                            ### EXPERINCE\n",
    "                x=items.find('ul',class_='top-jd-dtl clearfix') #extracting location\n",
    "                location=x.find('span')['title']                                                           ### LOCATION\n",
    "                key_skill=items.find('span',class_='srp-skills').text # exttracting key skills\n",
    "                key_skills=key_skill.strip()                                                               ### KEY SKILLS\n",
    "                job_desc=items.find('ul',class_='list-job-dtl clearfix').text #extracting job description\n",
    "                a=items.find('label').text\n",
    "                replace=\"\"\n",
    "                job_description=re.sub(a,replace,job_desc)\n",
    "                final_job_desc=job_description.strip()\n",
    "                aa=\"KeySkills:\"\n",
    "                bb=re.sub(aa,replace,final_job_desc)\n",
    "                k=bb.replace(key_skills,\"\")\n",
    "                l=k.replace(\"More Details\",\"\")\n",
    "                final_job_description=l.strip()                                                            ### JOB DESCRIPTION\n",
    "                job_url=items.find('a')['href'] ##extracting job link                                      ### JOB LINK\n",
    "                mydict={}\n",
    "                mydict['Job Title']=job_title ## inserting all the above data in a dictionary.\n",
    "                mydict['Company Name']=company_name\n",
    "                mydict['Experince']=experince\n",
    "                mydict['Location']=location\n",
    "                mydict['Job Description']=final_job_description\n",
    "                mydict['Key Skills']=key_skills\n",
    "                mydict['Job Detail Link']=job_url\n",
    "                mylst.append(mydict)## appending the above dictionary in a list to perform convertion of this data into a  table using pandas libra.\n",
    "        def creating_excelsheet():\n",
    "                import pandas as pd \n",
    "                df=pd.DataFrame(mylst) ## pandas is a in bulit library of python used to create a table of above data.The data should be in the form of list of dictionary.\n",
    "                df.to_excel('info_of_jobs.xlsx') ## to export the above table into excel sheet.\n",
    "        return creating_excelsheet()\n",
    "    return extracig_data()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7af90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Times_job_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
